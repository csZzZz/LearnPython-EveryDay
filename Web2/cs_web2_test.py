# 2017/02/18
# 2
# ========

# 定义log函数


def log(*args, **kwargs):
    print('log', *args, **kwargs)


# 实现函数
def path_with_query(path, query):
    """
    :param path: 是一个字符串
    :param query: 是一个字典
    :return: 返回一个拼接后的 url
    """
    keys_list = list(query.keys())
    values_list = list(query.values())
    length = len(query)
    string = ''
    for i in range(length):
        if i == length - 1:
            string += str(keys_list[i]) + '=' + str(values_list[i])
        else:
            string += str(keys_list[i]) + '=' + str(values_list[i]) + '&'
    return path + '?' + string


def test_path_with_query():
    # 注意 height 是一个数字
    path = '/'
    query = {
        'name': 'gua',
        'height': 169,
    }
    expected = [
        '/?name=gua&height=169',
        '/?height=169&name=gua',
    ]
    # log(path_with_query(path, query))
    # NOTE, 字典是无序的, 不知道哪个参数在前面, 所以这样测试
    assert path_with_query(path, query) in expected


# 测试函数通过
test_path_with_query()

# 作业 2.2
#
# 为作业1 的 get 函数增加一个参数 query
# query 是字典


# 作业 2.3
#
# 实现函数
def header_from_dict(headers):
    '''
    headers 是一个字典
    范例如下
    对于
    {
    	'Content-Type': 'text/html',
        'Content-Length': 127,
    }
    返回如下 str
    'Content-Type: text/html\r\nContent-Length: 127\r\n'
    '''
    pass


# 作业 2.4
#
# 为作业 2.3 写测试


# 作业 2.5
#
"""
豆瓣电影 Top250 页面链接如下
https://movie.douban.com/top250
我们的 client_ssl.py 已经可以获取 https 的内容了
这页一共有 25 个条目

所以现在的程序就只剩下了解析 HTML

请观察页面的规律，解析出
1，电影名
2，分数
3，评价人数
4，引用语（比如第一部肖申克的救赎中的「希望让人自由。」）

解析方式可以用任意手段，如果你没有想法，用字符串查找匹配比较好(find 特征字符串加切片)
"""


# 作业 2.6
#
"""
通过在浏览器页面中访问 豆瓣电影 top250 可以发现
1, 每页 25 个条目
2, 下一页的 URL 如下
https://movie.douban.com/top250?start=25

因此可以用循环爬出豆瓣 top250 的所有网页

于是就有了豆瓣电影 top250 的所有网页

由于这 10 个页面都是一样的结构，所以我们只要能解析其中一个页面就能循环得到所有信息

所以现在的程序就只剩下了解析 HTML

请观察规律，解析出
1，电影名
2，分数
3，评价人数
4，引用语（比如第一部肖申克的救赎中的「希望让人自由。」）

解析方式可以用任意手段，如果你没有想法，用字符串查找匹配比较好(find 特征字符串加切片)
"""
